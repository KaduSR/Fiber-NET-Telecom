1. api/src/services/ai/providers/IAIProvider.ts (Atualizado)
Este arquivo define a interface que todos os seus provedores de IA devem seguir. Ele é a base para a modularidade.

typescript
Copiar

// api/src/services/ai/providers/IAIProvider.ts

export interface AIMessage {
  role: "user" | "assistant" | "system";
  content: string;
}

export interface AIResponse {
  content: string;
  provider: string;
  model?: string; // Adicionado para identificar o modelo específico usado
  tokensUsed?: number; // Adicionado para métricas de custo
  finishReason?: string; // Adicionado para depuração
}

export interface AIProviderConfig {
  apiKey: string;
  model: string;
  temperature?: number;
  maxTokens?: number;
  timeout?: number;
}

export interface IAIProvider {
  name: string;
  isAvailable: boolean; // Para health checks

  /**
   * Envia uma lista de mensagens para o provedor de IA e retorna a resposta.
   * @param messages O histórico da conversa, incluindo a mensagem atual do usuário.
   * @param customConfig Configurações específicas para esta chamada (opcional).
   * @returns Uma promessa que resolve para a resposta da IA.
   */
  chat(messages: AIMessage[], customConfig?: Partial<AIProviderConfig>): Promise<AIResponse>;

  /**
   * Realiza um health check para verificar a disponibilidade do provedor.
   * @returns Uma promessa que resolve para true se o provedor estiver saudável, false caso contrário.
   */
  healthCheck(): Promise<boolean>;

  /**
   * Estima o custo de uma requisição com base nas mensagens.
   * @param messages As mensagens a serem enviadas.
   * @returns O custo estimado em dólares.
   */
  estimateCost(messages: AIMessage[]): number;
}
2. api/src/services/ai/providers/OpenAIProvider.ts (Novo)
Implementação para o OpenAI (GPT-4o, GPT-3.5, etc.).

typescript
Copiar

// api/src/services/ai/providers/OpenAIProvider.ts

import OpenAI from 'openai';
import { IAIProvider, AIMessage, AIResponse, AIProviderConfig } from './IAIProvider';

export class OpenAIProvider implements IAIProvider {
  name = 'OpenAI';
  isAvailable = true; // Assume que está disponível até que um erro ocorra
  private client: OpenAI;
  private config: AIProviderConfig;

  constructor(config: AIProviderConfig) {
    this.config = {
      temperature: 0.7,
      maxTokens: 2000,
      timeout: 30000, // 30 segundos
      ...config,
    };

    this.client = new OpenAI({
      apiKey: this.config.apiKey,
      timeout: this.config.timeout,
    });
  }

  async chat(messages: AIMessage[], customConfig?: Partial<AIProviderConfig>): Promise<AIResponse> {
    try {
      const response = await this.client.chat.completions.create({
        model: customConfig?.model || this.config.model,
        messages: messages.map(m => ({
          role: m.role,
          content: m.content,
        })),
        temperature: customConfig?.temperature || this.config.temperature,
        max_tokens: customConfig?.maxTokens || this.config.maxTokens,
      });

      return {
        content: response.choices[0].message.content || '',
        provider: this.name,
        model: response.model,
        tokensUsed: response.usage?.total_tokens,
        finishReason: response.choices[0].finish_reason,
      };
    } catch (error: any) {
      console.error(`OpenAIProvider Error: ${error.message}`);
      this.isAvailable = false; // Marca como indisponível em caso de erro
      throw new Error(`OpenAI Error: ${error.message}`);
    }
  }

  async healthCheck(): Promise<boolean> {
    try {
      // Tenta listar modelos para verificar a conectividade e a chave API
      await this.client.models.list();
      this.isAvailable = true;
      return true;
    } catch (error) {
      console.error(`OpenAIProvider Health Check Failed: ${error}`);
      this.isAvailable = false;
      return false;
    }
  }

  estimateCost(messages: AIMessage[]): number {
    // Estimativa de custo para GPT-4o (preços podem variar, consulte a documentação da OpenAI)
    // Exemplo: GPT-4o: $5.00 / 1M input tokens, $15.00 / 1M output tokens
    const inputTokensPerMillion = 5.00;
    const outputTokensPerMillion = 15.00;

    const totalInputChars = messages.reduce((sum, m) => sum + m.content.length, 0);
    const estimatedInputTokens = Math.ceil(totalInputChars / 4); // Aproximação de tokens por caractere

    // Estimamos 500 tokens de saída para uma resposta média
    const estimatedOutputTokens = 500; 

    const inputCost = (estimatedInputTokens / 1_000_000) * inputTokensPerMillion;
    const outputCost = (estimatedOutputTokens / 1_000_000) * outputTokensPerMillion;

    return inputCost + outputCost;
  }
}
3. api/src/services/ai/providers/ClaudeProvider.ts (Novo)
Implementação para o Anthropic Claude (Claude 3.5 Sonnet, etc.).

typescript
Copiar

// api/src/services/ai/providers/ClaudeProvider.ts

import Anthropic from '@anthropic-ai/sdk';
import { IAIProvider, AIMessage, AIResponse, AIProviderConfig } from './IAIProvider';

export class ClaudeProvider implements IAIProvider {
  name = 'Claude';
  isAvailable = true;
  private client: Anthropic;
  private config: AIProviderConfig;

  constructor(config: AIProviderConfig) {
    this.config = {
      temperature: 0.7,
      maxTokens: 2000,
      timeout: 30000,
      ...config,
    };

    this.client = new Anthropic({
      apiKey: this.config.apiKey,
      timeout: this.config.timeout,
    });
  }

  async chat(messages: AIMessage[], customConfig?: Partial<AIProviderConfig>): Promise<AIResponse> {
    try {
      // Claude espera a mensagem do sistema separada das mensagens de conversação
      const systemMessage = messages.find(m => m.role === 'system')?.content || '';
      const conversationMessages = messages
        .filter(m => m.role !== 'system')
        .map(m => ({
          role: m.role as 'user' | 'assistant', // Claude só aceita 'user' ou 'assistant' aqui
          content: m.content,
        }));

      const response = await this.client.messages.create({
        model: customConfig?.model || this.config.model,
        max_tokens: customConfig?.maxTokens || this.config.maxTokens,
        temperature: customConfig?.temperature || this.config.temperature,
        system: systemMessage,
        messages: conversationMessages,
      });

      return {
        content: response.content[0].type === 'text' ? response.content[0].text : '',
        provider: this.name,
        model: response.model,
        tokensUsed: response.usage.input_tokens + response.usage.output_tokens,
        finishReason: response.stop_reason || undefined,
      };
    } catch (error: any) {
      console.error(`ClaudeProvider Error: ${error.message}`);
      this.isAvailable = false;
      throw new Error(`Claude Error: ${error.message}`);
    }
  }

  async healthCheck(): Promise<boolean> {
    try {
      // Tenta fazer uma requisição mínima para verificar a conectividade
      await this.client.messages.create({
        model: this.config.model,
        max_tokens: 10, // Requisição pequena para não gastar muito
        messages: [{ role: 'user', content: 'ping' }],
      });
      this.isAvailable = true;
      return true;
    } catch (error) {
      console.error(`ClaudeProvider Health Check Failed: ${error}`);
      this.isAvailable = false;
      return false;
    }
  }

  estimateCost(messages: AIMessage[]): number {
    // Estimativa de custo para Claude 3.5 Sonnet (preços podem variar)
    // Exemplo: Claude 3.5 Sonnet: $3.00 / 1M input tokens, $15.00 / 1M output tokens
    const inputTokensPerMillion = 3.00;
    const outputTokensPerMillion = 15.00;

    const totalInputChars = messages.reduce((sum, m) => sum + m.content.length, 0);
    const estimatedInputTokens = Math.ceil(totalInputChars / 4);

    const estimatedOutputTokens = 500; 

    const inputCost = (estimatedInputTokens / 1_000_000) * inputTokensPerMillion;
    const outputCost = (estimatedOutputTokens / 1_000_000) * outputTokensPerMillion;

    return inputCost + outputCost;
  }
}
4. api/src/services/ai/providers/GroqProvider.ts (Novo)
Implementação para o Groq (Llama 3.1, Mixtral, etc.). Conhecido pela velocidade e custo-benefício.

typescript
Copiar

// api/src/services/ai/providers/GroqProvider.ts

import Groq from 'groq-sdk';
import { IAIProvider, AIMessage, AIResponse, AIProviderConfig } from './IAIProvider';

export class GroqProvider implements IAIProvider {
  name = 'Groq';
  isAvailable = true;
  private client: Groq;
  private config: AIProviderConfig;

  constructor(config: AIProviderConfig) {
    this.config = {
      temperature: 0.7,
      maxTokens: 2000,
      ...config, // Groq SDK não tem timeout direto no construtor, mas pode ser configurado na chamada
    };

    this.client = new Groq({
      apiKey: this.config.apiKey,
    });
  }

  async chat(messages: AIMessage[], customConfig?: Partial<AIProviderConfig>): Promise<AIResponse> {
    try {
      const response = await this.client.chat.completions.create({
        model: customConfig?.model || this.config.model,
        messages: messages.map(m => ({
          role: m.role,
          content: m.content,
        })),
        temperature: customConfig?.temperature || this.config.temperature,
        max_tokens: customConfig?.maxTokens || this.config.maxTokens,
        // timeout: customConfig?.timeout || this.config.timeout, // Groq SDK não tem esta opção aqui
      });

      return {
        content: response.choices[0].message.content || '',
        provider: this.name,
        model: response.model,
        tokensUsed: response.usage?.total_tokens,
        finishReason: response.choices[0].finish_reason,
      };
    } catch (error: any) {
      console.error(`GroqProvider Error: ${error.message}`);
      this.isAvailable = false;
      throw new Error(`Groq Error: ${error.message}`);
    }
  }

  async healthCheck(): Promise<boolean> {
    try {
      // Tenta fazer uma requisição mínima para verificar a conectividade
      await this.client.chat.completions.create({
        model: this.config.model,
        messages: [{ role: 'user', content: 'ping' }],
        max_tokens: 5, // Requisição pequena
      });
      this.isAvailable = true;
      return true;
    } catch (error) {
      console.error(`GroqProvider Health Check Failed: ${error}`);
      this.isAvailable = false;
      return false;
    }
  }

  estimateCost(messages: AIMessage[]): number {
    // Groq é conhecido por ser muito econômico, e para muitos modelos Llama, é gratuito ou tem um custo muito baixo.
    // Para Llama 3.1 70B, o custo é geralmente muito baixo ou gratuito em planos de uso razoáveis.
    // Consulte a documentação do Groq para os preços mais recentes.
    return 0; // Assumindo custo zero para uso padrão
  }
}
5. api/src/services/ai/providers/GeminiProvider.ts (Atualizado)
Atualizando o GeminiProvider para incluir isAvailable, healthCheck e estimateCost.

typescript
Copiar

// api/src/services/ai/providers/GeminiProvider.ts

import { GoogleGenerativeAI } from "@google/generative-ai";
import { IAIProvider, AIMessage, AIResponse, AIProviderConfig } from "./IAIProvider";

export class GeminiProvider implements IAIProvider {
  name = "Gemini";
  isAvailable = true;
  private client: GoogleGenerativeAI;
  private config: AIProviderConfig;

  constructor(config: AIProviderConfig) {
    this.config = {
      temperature: 0.7,
      maxTokens: 2000,
      ...config,
    };

    this.client = new GoogleGenerativeAI(this.config.apiKey);
  }

  async chat(messages: AIMessage[], customConfig?: Partial<AIProviderConfig>): Promise<AIResponse> {
    try {
      const model = this.client.getGenerativeModel({ 
        model: customConfig?.model || this.config.model,
      });

      // Gemini aceita um array de objetos com role e parts (content)
      const formattedMessages = messages.map(msg => ({
        role: msg.role === 'system' ? 'user' : msg.role, // Gemini não tem 'system' role direto em chat, usa 'user' para instruções
        parts: [{ text: msg.content }],
      }));

      const result = await model.generateContent({
        contents: formattedMessages,
        generationConfig: {
          temperature: customConfig?.temperature || this.config.temperature,
          maxOutputTokens: customConfig?.maxTokens || this.config.maxTokens,
        },
      });
      const response = result.response;

      return {
        content: response.text(),
        provider: this.name,
        model: this.config.model, // O modelo usado
        tokensUsed: response.usageMetadata?.totalTokenCount,
      };
    } catch (error: any) {
      console.error(`GeminiProvider Error: ${error.message}`);
      this.isAvailable = false;
      throw new Error(`Gemini Error: ${error.message}`);
    }
  }

  async healthCheck(): Promise<boolean> {
    try {
      const model = this.client.getGenerativeModel({ model: this.config.model });
      await model.generateContent('ping'); // Requisição mínima
      this.isAvailable = true;
      return true;
    } catch (error) {
      console.error(`GeminiProvider Health Check Failed: ${error}`);
      this.isAvailable = false;
      return false;
    }
  }

  estimateCost(messages: AIMessage[]): number {
    // Estimativa de custo para Gemini 1.5 Pro (preços podem variar)
    // Exemplo: Gemini 1.5 Pro: $3.50 / 1M input tokens, $10.50 / 1M output tokens
    const inputTokensPerMillion = 3.50;
    const outputTokensPerMillion = 10.50;

    const totalInputChars = messages.reduce((sum, m) => sum + m.content.length, 0);
    const estimatedInputTokens = Math.ceil(totalInputChars / 4);

    const estimatedOutputTokens = 500; 

    const inputCost = (estimatedInputTokens / 1_000_000) * inputTokensPerMillion;
    const outputCost = (estimatedOutputTokens / 1_000_000) * outputTokensPerMillion;

    return inputCost + outputCost;
  }
}
6. api/src/services/ai/AIOrchestrator.ts (Atualizado)
Este orquestrador agora pode gerenciar múltiplos provedores e fazer fallback.

typescript
Copiar

// api/src/services/ai/AIOrchestrator.ts

import { IAIProvider, AIMessage, AIResponse, AIProviderConfig } from "./providers/IAIProvider";
import { OpenAIProvider } from "./providers/OpenAIProvider";
import { ClaudeProvider } from "./providers/ClaudeProvider";
import { GeminiProvider } from "./providers/GeminiProvider";
import { GroqProvider } from "./providers/GroqProvider";

interface ProviderEntry {
  provider: IAIProvider;
  priority: number; // Menor número = maior prioridade
  enabled: boolean;
  useFor?: ('simple' | 'medium' | 'complex')[]; // Para roteamento inteligente
}

export class AIOrchestrator {
  private providers: Map<string, ProviderEntry> = new Map();
  private healthCheckInterval: NodeJS.Timeout | null = null;

  constructor() {
    this.initializeProviders();
    this.startHealthChecks();
  }

  private initializeProviders() {
    // Carregar configurações do .env
    const config = {
      openai: {
        apiKey: process.env.OPENAI_API_KEY || '',
        model: 'gpt-4o',
      },
      claude: {
        apiKey: process.env.ANTHROPIC_API_KEY || '',
        model: 'claude-3-5-sonnet-20241022',
      },
      gemini: {
        apiKey: process.env.GOOGLE_API_KEY || '',
        model: 'gemini-1.5-pro',
      },
      groq: {
        apiKey: process.env.GROQ_API_KEY || '',
        model: 'llama-3.1-70b-versatile', // Ou outro modelo Groq como 'mixtral-8x7b-32768'
      },
    };

    // Registrar providers com suas prioridades e casos de uso
    // A ordem aqui define a prioridade inicial se não houver roteamento inteligente
    if (config.groq.apiKey) {
      this.registerProvider('groq', new GroqProvider(config.groq), 1, ['simple']); // Mais rápido e barato para simples
    }

    if (config.gemini.apiKey) {
      this.registerProvider('gemini', new GeminiProvider(config.gemini), 2, ['simple', 'medium']); // Bom custo-benefício
    }

    if (config.openai.apiKey) {
      this.registerProvider('openai', new OpenAIProvider(config.openai), 3, ['medium', 'complex']); // Qualidade alta
    }

    if (config.claude.apiKey) {
      this.registerProvider('claude', new ClaudeProvider(config.claude), 4, ['complex']); // Qualidade premium para complexos
    }
  }

  private registerProvider(
    name: string, 
    provider: IAIProvider, 
    priority: number,
    useFor: ('simple' | 'medium' | 'complex')[] = ['simple', 'medium', 'complex']
  ) {
    if (provider.config.apiKey) { // Só registra se a API Key estiver presente
      this.providers.set(name, {
        provider,
        priority,
        enabled: true,
        useFor,
      });
      console.log(`Provider ${name} registrado com prioridade ${priority}.`);
    } else {
      console.warn(`API Key para ${name} não encontrada. Provider não será registrado.`);
    }
  }

  private startHealthChecks() {
    // Health check a cada 2 minutos
    this.healthCheckInterval = setInterval(() => {
      this.performHealthChecks();
    }, 120000); // 2 minutos
  }

  /**
   * MÉTODO PRINCIPAL - Envia mensagem e retorna resposta, com fallback automático.
   */
  async chat(messages: AIMessage[], options?: {
    preferredProvider?: string;
    complexity?: 'simple' | 'medium' | 'complex';
  }): Promise<AIResponse> {
    const complexity = options?.complexity || this.analyzeComplexity(messages);

    // 1. Tentar provedor preferencial, se especificado e disponível
    if (options?.preferredProvider) {
      const entry = this.providers.get(options.preferredProvider);
      if (entry?.enabled && entry.provider.isAvailable) {
        try {
          console.log(`Tentando provedor preferencial: ${options.preferredProvider}`);
          return await entry.provider.chat(messages);
        } catch (error) {
          console.warn(`Provedor preferencial ${options.preferredProvider} falhou, tentando fallback...`);
          entry.provider.isAvailable = false; // Marca como indisponível
        }
      }
    }

    // 2. Filtrar provedores adequados para a complexidade e disponíveis
    const availableProviders = Array.from(this.providers.entries())
      .filter(([_, entry]) => 
        entry.enabled && 
        entry.provider.isAvailable &&
        (entry.useFor?.includes(complexity) || !entry.useFor) // Se não tem 'useFor', serve para tudo
      )
      .sort((a, b) => a[1].priority - b[1].priority); // Ordena por prioridade

    // 3. Tentar cada provedor em ordem de prioridade
    for (const [name, entry] of availableProviders) {
      try {
        console.log(`Tentando provedor: ${name} (complexidade: ${complexity})`);
        return await entry.provider.chat(messages);
      } catch (error: any) {
        console.error(`Provedor ${name} falhou: ${error.message}`);
        entry.provider.isAvailable = false; // Marca como indisponível
        // Continua para o próximo provedor
      }
    }

    // Se todos falharem
    throw new Error('Todos os provedores de IA falharam ou estão indisponíveis.');
  }

  /**
   * Analisa a complexidade da mensagem para roteamento inteligente.
   */
  private analyzeComplexity(messages: AIMessage[]): 'simple' | 'medium' | 'complex' {
    const lastUserMessage = messages
      .filter(m => m.role === 'user')
      .pop()?.content.toLowerCase() || '';

    // Palavras-chave simples
    const simpleKeywords = ['oi', 'olá', 'obrigado', 'tchau', 'status', 'horário', 'agradeço', 'bom dia', 'boa tarde'];
    if (simpleKeywords.some(k => lastUserMessage.includes(k))) {
      return 'simple';
    }

    // Palavras-chave complexas
    const complexKeywords = [
      'problema', 'não funciona', 'erro', 'reclamação', 'cancelar', 
      'contrato', 'jurídico', 'reembolso', 'velocidade', 'instabilidade', 'suporte técnico'
    ];
    if (complexKeywords.some(k => lastUserMessage.includes(k))) {
      return 'complex';
    }

    // Mensagens longas ou com muitas perguntas podem ser complexas
    if (lastUserMessage.length > 150 || (lastUserMessage.match(/\?/g) || []).length > 1) {
      return 'complex';
    }

    return 'medium';
  }

  /**
   * Realiza health checks em todos os provedores registrados.
   */
  private async performHealthChecks() {
    console.log('Executando health checks nos provedores de IA...');

    for (const [name, entry] of this.providers.entries()) {
      if (!entry.enabled) {
        console.log(`Provedor ${name} está desabilitado.`);
        continue;
      }

      const wasAvailable = entry.provider.isAvailable;
      const isHealthy = await entry.provider.healthCheck();

      if (isHealthy && !wasAvailable) {
        console.log(`Provedor ${name} voltou a ficar DISPONÍVEL.`);
      } else if (!isHealthy && wasAvailable) {
        console.warn(`Provedor ${name} ficou INDISPONÍVEL.`);
      } else {
        console.log(`Provedor ${name}: ${isHealthy ? 'OK' : 'FALHA'}`);
      }
      entry.provider.isAvailable = isHealthy;
    }
  }

  /**
   * Habilita ou desabilita um provedor manualmente.
   */
  setProviderEnabled(name: string, enabled: boolean) {
    const entry = this.providers.get(name);
    if (entry) {
      entry.enabled = enabled;
      console.log(`Provedor ${name} ${enabled ? 'habilitado' : 'desabilitado'}.`);
    } else {
      console.warn(`Provedor ${name} não encontrado.`);
    }
  }

  /**
   * Obtém o status atual de todos os provedores.
   */
  getProvidersStatus() {
    return Array.from(this.providers.entries()).map(([name, entry]) => ({
      name,
      enabled: entry.enabled,
      available: entry.provider.isAvailable,
      priority: entry.priority,
      useFor: entry.useFor,
      estimatedCostPerQuery: entry.provider.estimateCost([{ role: 'user', content: 'teste' }]), // Custo de uma query de teste
    }));
  }

  /**
   * Limpa o intervalo de health checks ao destruir a instância.
   */
  destroy() {
    if (this.healthCheckInterval) {
      clearInterval(this.healthCheckInterval);
      this.healthCheckInterval = null;
    }
    console.log('AIOrchestrator destruído. Health checks parados.');
  }
}

// Exporta uma instância única do orquestrador para ser usada em toda a aplicação
export const aiOrchestrator = new AIOrchestrator();
7. api/src/services/ai/index.ts (Atualizado)
Este é o arquivo que você vai usar para selecionar qual provedor de IA será o principal (ou o único, se você não quiser o orquestrador).

typescript
Copiar

// api/src/services/ai/index.ts

// Importe todos os provedores disponíveis
import { OpenAIProvider } from "./providers/OpenAIProvider";
import { ClaudeProvider } from "./providers/ClaudeProvider";
import { GeminiProvider } from "./providers/GeminiProvider";
import { GroqProvider } from "./providers/GroqProvider";
import { AIOrchestrator } from "./AIOrchestrator";
import { IAIProvider } from "./providers/IAIProvider";

// --- ESCOLHA SEU MODO DE OPERAÇÃO ---

// Opção 1: Usar o Orquestrador (RECOMENDADO para resiliência e roteamento inteligente)
// O orquestrador gerencia múltiplos provedores, faz health checks e fallback automático.
export const activeAIProvider: IAIProvider = new AIOrchestrator();


// Opção 2: Usar um único provedor diretamente (se você não precisa de fallback ou roteamento)
// Descomente a linha do provedor que deseja usar e comente a linha do AIOrchestrator acima.
/*
export const activeAIProvider: IAIProvider = new GeminiProvider({
  apiKey: process.env.GOOGLE_API_KEY!,
  model: "gemini-1.5-pro"
});
*/

/*
export const activeAIProvider: IAIProvider = new OpenAIProvider({
  apiKey: process.env.OPENAI_API_KEY!,
  model: "gpt-4o"
});
*/

/*
export const activeAIProvider: IAIProvider = new ClaudeProvider({
  apiKey: process.env.ANTHROPIC_API_KEY!,
  model: "claude-3-5-sonnet-20241022"
});
*/

/*
export const activeAIProvider: IAIProvider = new GroqProvider({
  apiKey: process.env.GROQ_API_KEY!,
  model: "llama-3.1-70b-versatile"
});
*/
8. api/src/api/controllers/supportController.ts (Atualizado)
O controller agora usa a instância activeAIProvider do index.ts.

typescript
Copiar

// api/src/api/controllers/supportController.ts

import { Request, Response } from "express";
import { activeAIProvider } from "../../services/ai"; // Importa o provedor ativo (pode ser o orquestrador ou um único)
import { AIMessage } from "../../services/ai/providers/IAIProvider";

export const supportAI = async (req: Request, res: Response) => {
  const { message, conversationHistory = [] } = req.body; // Recebe histórico e mensagem

  if (!message) {
    return res.status(400).json({ ok: false, error: "Mensagem é obrigatória." });
  }

  try {
    // Adiciona a mensagem do usuário ao histórico
    const userMessage: AIMessage = { role: "user", content: message };
    const fullConversation: AIMessage[] = [...conversationHistory, userMessage];

    // Aqui você pode adicionar lógica para buscar o contexto do cliente
    // Ex: const customerContext = await getCustomerContext(req.user.id);
    const customerContext = {
      customerName: "Kadu",
      currentPlan: "Fibra 500Mbps",
      networkStatus: "online",
      hasPendingBills: false,
    };

    // Cria a mensagem de sistema com o contexto do cliente
    const systemPrompt = `Você é o assistente virtual de um provedor de internet (ISP) chamado FiberNet.
    Seu objetivo é ajudar o cliente de forma eficiente e amigável.

    INFORMAÇÕES DO CLIENTE:
    - Nome: ${customerContext.customerName}
    - Plano: ${customerContext.currentPlan}
    - Status da conexão: ${customerContext.networkStatus}
    - Débitos pendentes: ${customerContext.hasPendingBills ? 'Sim' : 'Não'}

    DIRETRIZES:
    - Seja proativo, empático e eficiente.
    - Ofereça soluções práticas e diretas.
    - Se houver problema de rede, explique a situação e dê uma previsão de resolução.
    - Para questões financeiras, seja claro sobre valores e datas.
    - Sempre que possível, resolva a questão sem a necessidade de transferir para um atendente humano.
    - Mantenha as respostas concisas e focadas no problema.
    - Se o cliente perguntar sobre "segunda via de boleto", direcione-o para a área de faturas.
    - Se o cliente perguntar sobre "velocidade da internet", peça para ele verificar no painel do cliente ou ofereça um teste de velocidade.
    `;

    const messagesToSend: AIMessage[] = [
      { role: "system", content: systemPrompt },
      ...fullConversation
    ];

    const result = await activeAIProvider.chat(messagesToSend);

    // Adiciona a resposta da IA ao histórico para a próxima interação
    const updatedConversation = [...fullConversation, { role: "assistant", content: result.content }];

    return res.json({
      ok: true,
      reply: result.content,
      provider: result.provider,
      model: result.model,
      tokensUsed: result.tokensUsed,
      conversationHistory: updatedConversation, // Retorna o histórico atualizado
    });
  } catch (error: any) {
    console.error("Erro no suporte AI:", error);
    return res.status(500).json({
      ok: false,
      error: "Desculpe, estou com dificuldades técnicas. Por favor, tente novamente mais tarde.",
      details: error.message,
    });
  }
};
9. api/src/api/routes/supportRoutes.ts (Novo)
typescript
Copiar

// api/src/api/routes/supportRoutes.ts

import { Router } from "express";
import { supportAI } from "../controllers/supportController";

export const supportRoutes = Router();

// Rota para o chatbot de IA
supportRoutes.post("/ai", supportAI);

// Rota para obter o status dos provedores de IA (útil para monitoramento)
// Se você estiver usando o AIOrchestrator, ele terá este método.
// Se estiver usando um provedor único, você pode adaptar ou remover.
import { activeAIProvider } from "../../services/ai";
if (activeAIProvider instanceof AIOrchestrator) {
  supportRoutes.get("/ai/status", (req, res) => {
    res.json({
      providers: activeAIProvider.getProvidersStatus(),
    });
  });
  // Rota para habilitar/desabilitar provedores manualmente
  supportRoutes.post("/ai/toggle-provider", (req, res) => {
    const { providerName, enabled } = req.body;
    activeAIProvider.setProviderEnabled(providerName, enabled);
    res.json({
      success: true,
      status: activeAIProvider.getProvidersStatus(),
    });
  });
}
10. api/src/api/routes/routes.ts (Atualizado)
Você precisará importar e usar as novas rotas de suporte no seu arquivo de rotas principal.

typescript
Copiar

// api/src/api/routes/routes.ts

import { Router } from 'express';
import { authRoutes } from './authRoutes';
import { dashboardRoutes } from './dashboardRoutes';
import { supportRoutes } from './supportRoutes'; // Importe as novas rotas de suporte

const router = Router();

router.use('/auth', authRoutes);
router.use('/dashboard', dashboardRoutes);
router.use('/support', supportRoutes); // Adicione as rotas de suporte aqui

export default router;
11. api/.env (Atualizado)
Adicione as chaves de API para os novos provedores.

dotenv
Copiar

# api/.env

# --- Chaves de API para Provedores de IA ---

# OpenAI
OPENAI_API_KEY=sk-...

# Anthropic (Claude)
ANTHROPIC_API_KEY=sk-ant-...

# Google (Gemini)
GOOGLE_API_KEY=AI...

# Groq
GROQ_API_KEY=gsk_...

# --- Outras variáveis de ambiente ---
NODE_ENV=development
PORT=3001
12. api/package.json (Atualizado)
Adicione as dependências dos novos SDKs.

json
Copiar

{
  "name": "mei-api",
  "version": "1.0.0",
  "scripts": {
    "dev": "tsx watch src/index.ts",
    "build": "tsc",
    "start": "node dist/index.js"
  },
  "dependencies": {
    "express": "^4.18.2",
    "ws": "^8.14.2",
    "openai": "^4.20.0",           // Adicionado
    "@anthropic-ai/sdk": "^0.9.0", // Adicionado
    "@google/generative-ai": "^0.1.3", // Já deve ter, mas confirme
    "groq-sdk": "^0.3.0",          // Adicionado
    "dotenv": "^16.3.1"
  },
  "devDependencies": {
    "@types/express": "^4.17.20",
    "@types/ws": "^8.5.8",
    "@types/node": "^20.8.0",
    "tsx": "^4.0.0",
    "typescript": "^5.2.2"
  }
}
13. api/src/index.ts (Atualizado)
Certifique-se de que o dotenv seja carregado no início e que o AIOrchestrator seja destruído corretamente ao desligar o servidor.

typescript
Copiar

// api/src/index.ts

import 'dotenv/config'; // Carrega as variáveis de ambiente do .env
import app from './app';
import { aiOrchestrator } from './services/ai/AIOrchestrator'; // Importa a instância do orquestrador

const PORT = process.env.PORT || 3001;

const server = app.listen(PORT, () => {
  console.log(`Servidor rodando na porta ${PORT}`);
  console.log('AI Orchestrator inicializado.');
});

// Lida com o desligamento gracioso do servidor
process.on('SIGTERM', () => {
  console.log('SIGTERM recebido. Encerrando servidor...');
  server.close(() => {
    console.log('Servidor HTTP encerrado.');
    aiOrchestrator.destroy(); // Limpa o intervalo de health checks do orquestrador
    process.exit(0);
  });
});

process.on('SIGINT', () => {
  console.log('SIGINT recebido. Encerrando servidor...');
  server.close(() => {
    console.log('Servidor HTTP encerrado.');
    aiOrchestrator.destroy(); // Limpa o intervalo de health checks do orquestrador
    process.exit(0);
  });
});
Próximos Passos:
Instale as novas dependências: Navegue até a pasta api e execute npm install ou yarn add openai @anthropic-ai/sdk groq-sdk.
Configure suas chaves de API: Preencha o arquivo api/.env com as chaves de API corretas para cada provedor que você pretende usar.
Inicie o backend: npm run dev (ou npm start após npm run build).
Teste: Você pode usar ferramentas como Postman ou Insomnia para enviar requisições POST para http://localhost:3001/api/support/ai com um corpo JSON como:
json
Copiar

    {
      "message": "Qual o status da minha conexão?",
      "conversationHistory": []
    }
E também testar `http://localhost:3001/api/support/ai/status` para ver o status dos provedores.
Agora você tem um sistema de IA robusto e modular no seu backend, pronto para ser integrado ao seu frontend React sem quebrar o layout!

 INSTRUÇÃO OFICIAL (copie e cole no seu README interno)
Instrução: Como trocar o suporte de IA sem alterar layout ou frontend

Todo o sistema de IA fica dentro de:
api/src/services/ai/

Todos os providers ficam em:
api/src/services/ai/providers/

Para trocar a IA usada no suporte, altere somente 1 arquivo:
api/src/services/ai/index.ts

Nesse arquivo, selecione o provider ativo:

ts
Copiar

   import { OpenAIProvider } from "./providers/OpenAIProvider";
   import { GeminiProvider } from "./providers/GeminiProvider";
   import { ClaudeProvider } from "./providers/ClaudeProvider";
   import { GroqProvider } from "./providers/GroqProvider";

   // Troque aqui a IA usada:
   export const activeAIProvider = new GeminiProvider({
     apiKey: process.env.GEMINI_API_KEY,
     model: "gemini-1.5-pro"
   });
Não é necessário alterar nenhum controller, rota, componente React, modal, layout ou service.
O suporte IA continuará funcionando normalmente.

O chatbot da área do cliente sempre chamará a rota:
POST /api/support/ai
e o backend se encarrega de decidir qual IA vai responder.

✔️ Backend pronto para funcionar (código necessário)
1. Interface única
api/src/services/ai/providers/IAIProvider.ts

ts
Copiar

export interface AIMessage {
  role: "user" | "assistant" | "system";
  content: string;
}

export interface AIResponse {
  content: string;
  provider: string;
}

export interface IAIProvider {
  name: string;
  chat(messages: AIMessage[]): Promise<AIResponse>;
}
2. Providers (Gemini exemplo)
api/src/services/ai/providers/GeminiProvider.ts

ts
Copiar

import { GoogleGenerativeAI } from "@google/generative-ai";
import { AIMessage, AIResponse, IAIProvider } from "./IAIProvider";

export class GeminiProvider implements IAIProvider {
  name = "Gemini";

  constructor(private config: { apiKey: string; model: string }) {}

  async chat(messages: AIMessage[]): Promise<AIResponse> {
    const genAI = new GoogleGenerativeAI(this.config.apiKey);
    const model = genAI.getGenerativeModel({ model: this.config.model });

    const prompt = messages.map(m => `${m.role}: ${m.content}`).join("\n");

    const result = await model.generateContent(prompt);

    return {
      content: result.response.text(),
      provider: this.name
    };
  }
}
3. Orquestrador de IA
api/src/services/ai/AIOrchestrator.ts

ts
Copiar

import { AIMessage } from "./providers/IAIProvider";
import { activeAIProvider } from "./index";

export class AIOrchestrator {
  async chat(messages: AIMessage[]) {
    return activeAIProvider.chat(messages);
  }
}

export const ai = new AIOrchestrator();
4. Arquivo onde troca a IA
api/src/services/ai/index.ts

ts
Copiar

import { GeminiProvider } from "./providers/GeminiProvider";
// import { OpenAIProvider } from "./providers/OpenAIProvider";
// import { ClaudeProvider } from "./providers/ClaudeProvider";
// import { GroqProvider } from "./providers/GroqProvider";

export const activeAIProvider = new GeminiProvider({
  apiKey: process.env.GEMINI_API_KEY!,
  model: "gemini-1.5-pro"
});
5. Endpoint de suporte
api/src/api/controllers/supportController.ts

ts
Copiar

import { Request, Response } from "express";
import { ai } from "../../services/ai/AIOrchestrator";

export const supportAI = async (req: Request, res: Response) => {
  const { message } = req.body;

  const result = await ai.chat([
    { role: "system", content: "Você é o suporte oficial do ISP." },
    { role: "user", content: message }
  ]);

  return res.json({
    ok: true,
    reply: result.content,
    provider: result.provider
  });
};
6. Rota
api/src/api/routes/supportRoutes.ts

ts
Copiar

import { Router } from "express";
import { supportAI } from "../controllers/supportController";

export const supportRoutes = Router();

supportRoutes.post("/ai", supportAI);
E importe no routes.ts principal.